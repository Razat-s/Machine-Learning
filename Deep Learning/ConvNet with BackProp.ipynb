{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "import math as math\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-3e89ca988f52>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/nishanth/env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/nishanth/env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "WARNING:tensorflow:From /home/nishanth/env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST data/train-images-idx3-ubyte.gz\n",
      "Extracting"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nishanth/env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MNIST data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST data/t10k-images-idx3-ubyte.gz\n",
      "Extracting"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nishanth/env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MNIST data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Load the MNIST dataset into numpy arrays\n",
    "Author: Alexandre Drouin\n",
    "License: BSD\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST data/\", one_hot=True)\n",
    "X_train = np.vstack([img.reshape((28, 28)) for img in mnist.train.images])\n",
    "y_train = mnist.train.labels\n",
    "X_test = np.vstack([img.reshape(28, 28) for img in mnist.test.images])\n",
    "y_test = mnist.test.labels\n",
    "del mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X train= (1540000, 28)\n",
      "shape of y train= (55000, 10)\n",
      "shape of X test= (280000, 28)\n",
      "shape of y test= (280000, 28)\n"
     ]
    }
   ],
   "source": [
    "print('shape of X train=',X_train.shape)\n",
    "print('shape of y train=',y_train.shape)\n",
    "print('shape of X test=',X_test.shape)\n",
    "print('shape of y test=',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train input volume= (55000, 1, 28, 28)\n",
      "shape of train labels= (55000, 10)\n",
      "shape of test input volume= (10000, 1, 28, 28)\n",
      "shape of test labels= (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "# reshaping numpy array into volume  for train and test set \n",
    "#################################################################\n",
    "X_train=np.reshape(X_train,(-1,1,28,28))\n",
    "y_train=np.reshape(y_train,(-1,10))\n",
    "X_test=np.reshape(X_test,(-1,1,28,28))\n",
    "y_test=np.reshape(y_test,(-1,10))\n",
    "print('shape of train input volume=',X_train.shape)\n",
    "print('shape of train labels=',y_train.shape)\n",
    "print('shape of test input volume=',X_test.shape)\n",
    "print('shape of test labels=',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train input volume= (1000, 1, 28, 28)\n",
      "shape of train labels= (1000, 10)\n",
      "shape of test input volume= (500, 1, 28, 28)\n",
      "shape of test labels= (500, 10)\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# subsample of dataset\n",
    "###########################################################\n",
    "X_train=X_train[0:1000,:,:,:]\n",
    "y_train=y_train[0:1000,:]\n",
    "X_test=X_test[0:500,:,:,:]\n",
    "y_test=y_test[0:500,:]\n",
    "print('shape of train input volume=',X_train.shape)\n",
    "print('shape of train labels=',y_train.shape)\n",
    "print('shape of test input volume=',X_test.shape)\n",
    "print('shape of test labels=',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_data=num_train=X_train.shape[0]\n",
    "num_test=X_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no. of convolutional layers\n",
    "N_conv=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv(num_data,C_o,W_o,H_o,x_padded,F,S,kernels,bias,output):\n",
    "    for i, j in zip(range(H_o), range(W_o)):\n",
    "        data_receptive_field = x_padded[:, :, i*S:i*S + F, j*S:j*S + F]\n",
    "        data_receptive_field = data_receptive_field.reshape(num_data, -1)\n",
    "        tmp_filter = kernels.reshape(N, -1)\n",
    "        tmp_data = np.array((data_receptive_field, )*N).transpose([1, 0, 2])\n",
    "        tmp_filter = np.array((tmp_filter,)*num_data)\n",
    "        convolution_value = np.sum(tmp_data*tmp_filter, axis = 2)\n",
    "        output[:, :, i, j] = convolution_value + bias \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "#  apply ReLU non-linearity on convolved image(output) #\n",
    "#  return activation volume (output) (variables are same)                  \n",
    "#########################################################\n",
    "def relu_activation(num_data,N,output):\n",
    "    for l in range(num_data):\n",
    "        for i in range(N):\n",
    "            output[l,i,:,:]=np.maximum(0,output[l,i,:,:])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#   this function take input as activation volume(act_output)  #\n",
    "#   and return pooled output volume (pool_output)              #\n",
    "#################################################################\n",
    "def pooling(num_data,C_p,W_p,H_p,pool_S,pool,act_output,pool_output):\n",
    "    for i, j in zip(range(H_p), range(W_p)):\n",
    "        data_receptive_field = act_output[:, :, i*pool_S:i*pool_S + pool, j*pool_S:j*pool_S + pool]\n",
    "        pool_output[:, :, i, j] = data_receptive_field.max(axis = (2, 3))\n",
    "           \n",
    "    return pool_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#   this function take input volume and return pooled      #\n",
    "#   output volume                                          #\n",
    "############################################################\n",
    "def convolutional_layer(S,N,F,pool,pool_S,pad,arr,kernels,bias):\n",
    "    \n",
    "    num_data,C,W,H=np.shape(arr)\n",
    "        \n",
    "    # padding of input images\n",
    "    x_padded = np.pad(arr, ((0, 0), (0, 0), (pad, pad), (pad, pad)), \"constant\")\n",
    "\n",
    "    #print(\"original input dimension =\",arr.shape)\n",
    "    #print(\"input dimension after padding=\",x_padded.shape)\n",
    "   \n",
    "    # ouput dimension\n",
    "    W_o=int(((W-F+(2*pad))/S)+1)\n",
    "    H_o=int(((H-F+(2*pad))/S)+1)\n",
    "    C_o=N\n",
    "    output=np.zeros((num_data,C_o,W_o,H_o))\n",
    "    #print(\"output dimension=\",output.shape)\n",
    "    \n",
    "    # convolved output image\n",
    "    output=conv(num_data,C_o,W_o,H_o,x_padded,F,S,kernels,bias,output)\n",
    "    \n",
    "    # activation image\n",
    "    act_output=relu_activation(num_data,N,output)\n",
    "    \n",
    "    num_data,C_a,W_a,H_a=act_output.shape\n",
    "    \n",
    "    # pooled output dimension\n",
    "    W_p=int(((W_a-pool)/pool_S)+1)\n",
    "    H_p=int(((H_a-pool)/pool_S)+1)\n",
    "    C_p=C_a\n",
    "    pool_output=np.zeros((num_data,C_p,W_p,H_p))\n",
    "    #print(\"pooled output dimension=\",pool_output.shape)\n",
    "    \n",
    "    # pooled output image\n",
    "    pooled_output=pooling(num_data,C_p,W_p,H_p,pool_S,pool,act_output,pool_output)\n",
    "    \n",
    "    return act_output,pooled_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convnet_layer={} # this dictionary will store pooled ouput volume of each convolutional layers\n",
    "activation_output={}\n",
    "kernels={}\n",
    "bias={}\n",
    "W_mlp={}\n",
    "b_mlp={}\n",
    "losses=[]\n",
    "weight=None\n",
    "train_accuracy=[]\n",
    "arr=X_train\n",
    "num_data=X_train.shape[0]\n",
    "convnet_layer[0]=arr\n",
    "epoch=int(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-- 0\n",
      "loss= 2.30258406994\n",
      "training accuracy 0.093\n",
      "EPOCH-- 1\n",
      "loss= 2.30241495534\n",
      "training accuracy 0.115\n",
      "EPOCH-- 2\n",
      "loss= 2.30216137089\n",
      "training accuracy 0.115\n"
     ]
    }
   ],
   "source": [
    "for t in range(epoch):\n",
    "    print(\"EPOCH--\",t)\n",
    "    for i in range(1,N_conv+1):\n",
    "        if i==1:\n",
    "            #print(\"CONVOLUTIONAL LAYER\",i)\n",
    "            # filter size\n",
    "            F=5\n",
    "            # no. of kernels\n",
    "            N=32\n",
    "            # stride\n",
    "            S=1\n",
    "            # padding\n",
    "            pad=int((F-1)/2)\n",
    "            # pooling size\n",
    "            pool=2\n",
    "            # pooling stride\n",
    "            pool_S=2\n",
    "            arra=convnet_layer[i-1]\n",
    "            if t==0:\n",
    "                C=convnet_layer[i-1].shape[1]\n",
    "                # initializing kernels     \n",
    "                kernels[1]=np.random.rand(N,C,F,F)\n",
    "                # initializing biases\n",
    "                bias[1]=np.zeros(N)\n",
    "\n",
    "\n",
    "            activation_output[i],convnet_layer[i]=convolutional_layer(S,N,F,pool,pool_S,pad,arr=convnet_layer[i-1],kernels=kernels[i],bias=bias[i])\n",
    "        if i==2:\n",
    "            #print(\"CONVOLUTIONAL LAYER\",i)\n",
    "            # filter size\n",
    "            F=5\n",
    "            # no. of kernels\n",
    "            N=64\n",
    "            # stride\n",
    "            S=1\n",
    "            # padding\n",
    "            pad=int((F-1)/2)\n",
    "            # pooling size\n",
    "            pool=2\n",
    "            # pooling stride\n",
    "            pool_S=2\n",
    "            arra=convnet_layer[i-1]\n",
    "            if t==0:\n",
    "                C=convnet_layer[i-1].shape[1]\n",
    "                # initializing kernels     \n",
    "                kernels[2]=np.random.rand(N,C,F,F)\n",
    "                # initializing biases\n",
    "                bias[2]=np.zeros(N)\n",
    "\n",
    "\n",
    "            activation_output[i],convnet_layer[i]=convolutional_layer(S,N,F,pool,pool_S,pad,arr=convnet_layer[i-1],kernels=kernels[i],bias=bias[i])\n",
    "    \n",
    "    #################################################################\n",
    "    # unraveling\n",
    "    ##################################################################\n",
    "    z=convnet_layer[N_conv]\n",
    "    conv_output=z\n",
    "    # reshaping convolutional output into vector\n",
    "    conv_vec=np.reshape(conv_output,(num_data,-1))\n",
    "    #print(\"shape of convolutional layer output as vector=\",conv_vec.shape)\n",
    "\n",
    "    # initializing weight matrix for conversion of convolutional output into Fully connected input\n",
    "\n",
    "    # size of input layer\n",
    "    nodes=1024\n",
    "\n",
    "    weight=1e-4*np.random.rand(conv_vec.shape[1],nodes)\n",
    "    fc_in=np.dot(conv_vec,weight)  \n",
    "\n",
    "    \n",
    "    ##########################################################    \n",
    "    X=fc_in\n",
    "    input_size=X.shape[1]\n",
    "    hidden_size=500\n",
    "    output_size=10\n",
    "    \n",
    "\n",
    "    std=1e-4\n",
    "    if t==0:\n",
    "        W1 = std * np.random.randn(input_size, hidden_size)\n",
    "        b1 = np.zeros(hidden_size)\n",
    "        W2 = std * np.random.randn(hidden_size, output_size)\n",
    "        b2 = np.zeros(output_size)\n",
    "\n",
    "    relu=lambda x: np.maximum(0,x)\n",
    "    h1=relu(np.dot(X,W1)+b1)\n",
    "    h2=np.dot(h1,W2)+b2\n",
    "    scores=h2\n",
    "\n",
    "\n",
    "    ###softmax loss\n",
    "    scores -=np.reshape(np.max(scores,axis=1),(num_data,1))\n",
    "    p = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)\n",
    "    index_correct_class=[range(num_data),np.argmax(y_train,axis=1)] #indexes of correct class\n",
    "    correct_class_score= np.reshape(p[index_correct_class[0],index_correct_class[1]],(num_data,1))\n",
    "\n",
    "    loss = np.sum(-np.log(correct_class_score))\n",
    "    loss /= num_data\n",
    "    \n",
    "    reg=5e-6\n",
    "    loss += reg * (np.sum(W1 * W1) + np.sum(W2 * W2))\n",
    "    print(\"loss=\",loss)\n",
    "    losses=np.append(losses,loss)\n",
    "    #print(\"size of output vector=\",p.shape) \n",
    "    \n",
    "    ###############################################################################################3\n",
    "    # Backward pass: compute gradients\n",
    "    grads = {}\n",
    "    # gradient on scores\n",
    "    dscores=p\n",
    "    dscores[index_correct_class] -=1\n",
    "    dscores/=num_data\n",
    "\n",
    "    #gradient on W2\n",
    "    grads['W2']=np.dot(h1.T,dscores)\n",
    "    #gradient on b2\n",
    "    grads['b2']=np.sum(dscores,axis=0)\n",
    "\n",
    "    #backprop to hidden layer\n",
    "    dhidden= np.dot(dscores, W2.T)\n",
    "    dhidden[h1 <=0] =0\n",
    "\n",
    "    #gradient on W2\n",
    "    grads['W1']= np.dot(X.T,dhidden)\n",
    "    #gradient on b2\n",
    "    grads['b1']=np.sum(dhidden,axis=0)\n",
    "\n",
    "\n",
    "    #adding regularization\n",
    "    grads['W2']+=reg*W2\n",
    "    grads['W1']+=reg*W1\n",
    "\n",
    "    learning_rate=1e-1\n",
    "\n",
    "    # updating parameters\n",
    "    W1 -=learning_rate*grads['W1']\n",
    "    W2 -=learning_rate*grads['W2']\n",
    "    b1 -=learning_rate*grads['b1']\n",
    "    b2 -=learning_rate*grads['b2']\n",
    "    W_mlp[1]=W1\n",
    "    W_mlp[2]=W2\n",
    "    b_mlp[1]=b1\n",
    "    b_mlp[2]=b2\n",
    "\n",
    "    # training accuracy\n",
    "    train_acc = (np.argmax(h2,1) == np.argmax(y_train,1)).mean()\n",
    "    print('training accuracy',train_acc)\n",
    "    train_accuracy=np.append(train_accuracy,train_acc)\n",
    "    #val_acc = (self.predict(X_val) == y_val).mean()\n",
    "    \n",
    "    #########################################################################\n",
    "    # backpropagation in unravel\n",
    "    dX= np.dot(dhidden,W1.T)\n",
    "    grads['weight']=np.dot(conv_vec.T,dX)\n",
    "\n",
    "\n",
    "    dconv_vec=np.dot(dX,weight.T)\n",
    "\n",
    "    weight -=learning_rate*grads['weight']\n",
    "    dconv_vec=np.reshape(dconv_vec,(conv_output.shape))\n",
    "    #print(dconv_vec.shape)\n",
    "    \n",
    "    ##############################################################################\n",
    "    \n",
    "    #############################################################################\n",
    "    #   pooling backward pass  in convolutional layer 2                         #\n",
    "    #############################################################################\n",
    "    dact2 = None\n",
    "    # pooling size\n",
    "    pool=2\n",
    "    # pooling stride\n",
    "    pool_S=2\n",
    "    N, C, H, W = activation_output[2].shape\n",
    "\n",
    "    H_prime = int((H + - pool)/pool_S + 1)\n",
    "    W_prime = int((W + - pool)/pool_S + 1)\n",
    "\n",
    "    q=activation_output[2]\n",
    "    dact2 = np.zeros_like(activation_output[2])\n",
    "\n",
    "\n",
    "    for i, j in zip(range(H_prime),range(W_prime)):\n",
    "        data_receptive_field = q[:, :, i*pool_S:i*pool_S + pool, j*pool_S:j*pool_S + pool]\n",
    "\n",
    "        data_roll = data_receptive_field.reshape(N*C, -1)\n",
    "        data_maxgrad = (data_roll == np.row_stack(data_roll.max(axis = 1))).astype(\"int\")\n",
    "        grad_term = (data_maxgrad*dconv_vec[:, :, i, j].reshape(N*C, 1)).reshape(N, C, pool, pool)\n",
    "\n",
    "        dact2[:, :, i*pool_S:i*pool_S + pool, j*pool_S:j*pool_S + pool] += grad_term\n",
    "\n",
    "    ############################################################################################################\n",
    "    dx2, dw2, db2 = None, None, None\n",
    "    #############################################################################\n",
    "    #  convolutional backward pass in convolutional layer 2                     #\n",
    "    #############################################################################\n",
    "    # filter size\n",
    "    f=5\n",
    "\n",
    "    # stride\n",
    "    S=1\n",
    "    # padding\n",
    "    pad=int((f-1)/2)\n",
    "\n",
    "    N, C, H, W = convnet_layer[1].shape\n",
    "    F, _, HH, WW = kernels[2].shape\n",
    "    H_prime =int((H + 2*pad - HH)/S + 1)\n",
    "    W_prime = int((W + 2*pad - WW)/S + 1)\n",
    "    dx2 = np.zeros_like(convnet_layer[1])\n",
    "    dw2 = np.zeros_like(kernels[2])\n",
    "    db2 = np.zeros_like(bias[2])\n",
    "\n",
    "    # Zero padding on x\n",
    "    x2_padded = np.pad(convnet_layer[1], ((0, 0), (0, 0), (pad, pad), (pad, pad)), \"constant\")\n",
    "    dx2_padded = np.zeros_like(x2_padded)\n",
    "\n",
    "    # Derivative for db2\n",
    "    db2 = np.sum(dact2, axis = (0, 2, 3)) # only remain axis for F, diffrent filters\n",
    "\n",
    "    for i, j in zip(range(H_prime), range(W_prime)):\n",
    "        data_receptive_field = x2_padded[:, :, i*S:i*S + HH, j*S:j*S + WW]\n",
    "\n",
    "        # Derivative for dw2\n",
    "        tmp_field = np.array((data_receptive_field,)*F).transpose([1, 0, 2, 3, 4]).reshape(N*F, -1)\n",
    "        dw_tmp = (tmp_field*dact2[:, :, i, j].reshape(N*F, 1)).reshape(N, F, C, HH, WW)\n",
    "        dw2 += dw_tmp.sum(axis = 0)\n",
    "\n",
    "        # Derivative for dx2\n",
    "        tmp_filter = np.array((kernels[2],)*N).reshape(N*F, -1)\n",
    "        dx_tmp = (tmp_filter*dact2[:, :, i, j].reshape(N*F, 1)).reshape(N, F, C, HH, WW)\n",
    "        dx2_padded[:, :, i*S:i*S + HH, j*S:j*S + WW] += dx_tmp.sum(axis = 1)\n",
    "    # Unpad for dx\n",
    "    dx2 = dx2_padded[:, :, 1:-1, 1:-1]\n",
    "\n",
    "    kernels[2] += dw2\n",
    "    bias[2] += db2\n",
    "    \n",
    "    ####################################################################################################3\n",
    "    #############################################################################\n",
    "    #   pooling backward pass  in convolutional layer 1                         #\n",
    "    #############################################################################\n",
    "    dact1 = None\n",
    "    # pooling size\n",
    "    pool=2\n",
    "    # pooling stride\n",
    "    pool_S=2\n",
    "    N, C, H, W = activation_output[1].shape\n",
    "\n",
    "    H_prime = int((H + - pool)/pool_S + 1)\n",
    "    W_prime = int((W + - pool)/pool_S + 1)\n",
    "\n",
    "    q=activation_output[1]\n",
    "    dact1 = np.zeros_like(activation_output[1])\n",
    "\n",
    "\n",
    "    for i, j in zip(range(H_prime),range(W_prime)):\n",
    "        data_receptive_field = q[:, :, i*pool_S:i*pool_S + pool, j*pool_S:j*pool_S + pool]\n",
    "\n",
    "        data_roll = data_receptive_field.reshape(N*C, -1)\n",
    "        data_maxgrad = (data_roll == np.row_stack(data_roll.max(axis = 1))).astype(\"int\")\n",
    "        grad_term = (data_maxgrad*dx2[:, :, i, j].reshape(N*C, 1)).reshape(N, C, pool, pool)\n",
    "\n",
    "        dact1[:, :, i*pool_S:i*pool_S + pool, j*pool_S:j*pool_S + pool] += grad_term\n",
    "        \n",
    "    ##############################################################################################\n",
    "    dx1, dw1, db1 = None, None, None\n",
    "    #############################################################################\n",
    "    #  convolutional backward pass in convolutional layer 1                     #\n",
    "    #############################################################################\n",
    "\n",
    "    # filter size\n",
    "    f=5\n",
    "\n",
    "    # stride\n",
    "    S=1\n",
    "    # padding\n",
    "    pad=int((f-1)/2)\n",
    "\n",
    "    N, C, H, W = convnet_layer[0].shape\n",
    "    F, _, HH, WW = kernels[1].shape\n",
    "    H_prime = int((H + 2*pad - HH)/S + 1)\n",
    "    W_prime = int((W + 2*pad - WW)/S + 1)\n",
    "    dx1 = np.zeros_like(convnet_layer[0])\n",
    "    dw1 = np.zeros_like(kernels[1])\n",
    "    db1 = np.zeros_like(bias[1])\n",
    "\n",
    "    # Zero padding on x1\n",
    "    x1_padded = np.pad(convnet_layer[0], ((0, 0), (0, 0), (pad, pad), (pad, pad)), \"constant\")\n",
    "    dx1_padded = np.zeros_like(x1_padded)\n",
    "\n",
    "    # Derivative for db1\n",
    "    db1 = np.sum(dact1, axis = (0, 2, 3)) # only remain axis for F, diffrent filters\n",
    "\n",
    "    for i, j in zip(range(H_prime), range(W_prime)):\n",
    "        data_receptive_field = x1_padded[:, :, i*S:i*S + HH, j*S:j*S + WW]\n",
    "\n",
    "        # Derivative for dw1\n",
    "        tmp_field = np.array((data_receptive_field,)*F).transpose([1, 0, 2, 3, 4]).reshape(N*F, -1)\n",
    "        dw_tmp = (tmp_field*dact1[:, :, i, j].reshape(N*F, 1)).reshape(N, F, C, HH, WW)\n",
    "        dw1 += dw_tmp.sum(axis = 0)\n",
    "\n",
    "        # Derivative for dx1\n",
    "        tmp_filter = np.array((kernels[1],)*N).reshape(N*F, -1)\n",
    "        dx_tmp = (tmp_filter*dact1[:, :, i, j].reshape(N*F, 1)).reshape(N, F, C, HH, WW)\n",
    "        dx1_padded[:, :, i*S:i*S + HH, j*S:j*S + WW] += dx_tmp.sum(axis = 1)\n",
    "    # Unpad for dx1\n",
    "    dx1 = dx1_padded[:, :, 1:-1, 1:-1]\n",
    "\n",
    "\n",
    "    kernels[1] += dw1\n",
    "    bias[1] += db1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing loss= 2.30249386659\n",
      "testing accuracy 0.09\n"
     ]
    }
   ],
   "source": [
    "convnet_layer={} # this dictionary will store pooled ouput volume of each convolutional layers\n",
    "activation_output={}\n",
    "\n",
    "test_losses=[]\n",
    "test_accuracy=[]\n",
    "arr=X_test\n",
    "num_data=X_test.shape[0]\n",
    "convnet_layer[0]=arr\n",
    "\n",
    "\n",
    "W1 = W_mlp[1]\n",
    "b1 = b_mlp[1]\n",
    "W2 = W_mlp[2]\n",
    "b2 = b_mlp[2]\n",
    "\n",
    "for i in range(1,N_conv+1):\n",
    "    if i==1:\n",
    "        #print(\"CONVOLUTIONAL LAYER\",i)\n",
    "        # filter size\n",
    "        F=5\n",
    "        # no. of kernels\n",
    "        N=32\n",
    "        # stride\n",
    "        S=1\n",
    "        # padding\n",
    "        pad=int((F-1)/2)\n",
    "        # pooling size\n",
    "        pool=2\n",
    "        # pooling stride\n",
    "        pool_S=2\n",
    "        arra=convnet_layer[i-1]\n",
    "        activation_output[i],convnet_layer[i]=convolutional_layer(S,N,F,pool,pool_S,pad,arr=convnet_layer[i-1],kernels=kernels[i],bias=bias[i])\n",
    "    if i==2:\n",
    "        #print(\"CONVOLUTIONAL LAYER\",i)\n",
    "        # filter size\n",
    "        F=5\n",
    "        # no. of kernels\n",
    "        N=64\n",
    "        # stride\n",
    "        S=1\n",
    "        # padding\n",
    "        pad=int((F-1)/2)\n",
    "        # pooling size\n",
    "        pool=2\n",
    "        # pooling stride\n",
    "        pool_S=2\n",
    "        arra=convnet_layer[i-1]\n",
    "        activation_output[i],convnet_layer[i]=convolutional_layer(S,N,F,pool,pool_S,pad,arr=convnet_layer[i-1],kernels=kernels[i],bias=bias[i])\n",
    "    \n",
    "#################################################################\n",
    "# unraveling\n",
    "##################################################################\n",
    "z=convnet_layer[N_conv]\n",
    "conv_output=z\n",
    "# reshaping convolutional output into vector\n",
    "conv_vec=np.reshape(conv_output,(num_data,-1))\n",
    "    \n",
    "# size of input layer\n",
    "nodes=1024\n",
    "fc_in=np.dot(conv_vec,weight)  \n",
    "\n",
    "##########################################################    \n",
    "X=fc_in\n",
    "input_size=X.shape[1]\n",
    "hidden_size=500\n",
    "output_size=10\n",
    "\n",
    "relu=lambda x: np.maximum(0,x)\n",
    "h1=relu(np.dot(X,W1)+b1)\n",
    "h2=np.dot(h1,W2)+b2\n",
    "scores=h2\n",
    "\n",
    "\n",
    "###softmax loss\n",
    "scores -=np.reshape(np.max(scores,axis=1),(num_data,1))\n",
    "p = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)\n",
    "index_correct_class=[range(num_data),np.argmax(y_test,axis=1)] #indexes of correct class\n",
    "correct_class_score= np.reshape(p[index_correct_class[0],index_correct_class[1]],(num_data,1))\n",
    "\n",
    "loss = np.sum(-np.log(correct_class_score))\n",
    "loss /= num_data\n",
    "    \n",
    "reg=5e-6\n",
    "loss += reg * (np.sum(W1 * W1) + np.sum(W2 * W2))\n",
    "print(\"testing loss=\",loss)\n",
    "\n",
    "    \n",
    "# training accuracy\n",
    "test_acc = (np.argmax(h2,1) == np.argmax(y_test,1)).mean()\n",
    "print('testing accuracy',test_acc)\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efd78d04128>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAERCAYAAABGhLFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efd78d04a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(range(epoch),losses,label='training loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('training loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efd7b434ac8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efd7b4b6828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epoch),train_accuracy,label='training accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('training accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
